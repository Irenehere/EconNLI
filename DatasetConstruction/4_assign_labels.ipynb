{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate negative pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import datasets\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer\n",
    "\n",
    "MODEL_NAME_OR_PATH=\"bert-base-uncased\"  \n",
    "MODEL_OUTPUT_PATH = \"models/bert-base-uncased\"\n",
    "\n",
    "model = AutoModel.from_pretrained(MODEL_NAME_OR_PATH).cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME_OR_PATH)\n",
    "\n",
    "def get_bert_embedding(sentence, model, tokenizer):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    for key in inputs.keys():\n",
    "        inputs[key] = inputs[key].cuda()\n",
    "    outputs = model(**inputs)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    return last_hidden_states[0][0].detach().cpu().numpy()\n",
    "\n",
    "def get_excluded_effects_index(df_pos, target_index):\n",
    "    target_wiki_page = df_pos.iloc[target_index]['wiki_page']\n",
    "    excluded_effects_index = df_pos[df_pos['wiki_page'] == target_wiki_page].index.tolist()\n",
    "    return excluded_effects_index\n",
    "\n",
    "df_train_pos = pd.read_csv('../Dataset/EconNLI_train_tmp.csv')\n",
    "\n",
    "# generate negative examples\n",
    "\n",
    "causes_embeddings = []\n",
    "effects_embeddings = []\n",
    "\n",
    "for row in tqdm(df_train_pos.iterrows(), total=len(df_train_pos)):\n",
    "    cause_embedding = get_bert_embedding(row[1]['cause'], model, tokenizer)\n",
    "    effect_embedding = get_bert_embedding(row[1]['effect'], model, tokenizer)\n",
    "    causes_embeddings.append(cause_embedding)\n",
    "    effects_embeddings.append(effect_embedding)\n",
    "\n",
    "causes_embeddings = np.array(causes_embeddings)\n",
    "effects_embeddings = np.array(effects_embeddings)\n",
    "\n",
    "cos_mat = cosine_similarity(causes_embeddings, effects_embeddings)\n",
    "\n",
    "assert cos_mat.shape == (len(df_train_pos), len(df_train_pos))\n",
    "\n",
    "neg_list = []\n",
    "\n",
    "for row in tqdm(df_train_pos.iterrows(), total=len(df_train_pos)):\n",
    "    wiki_page = row[1]['wiki_page']\n",
    "    sentence = row[1]['sentence']\n",
    "    cause = row[1]['cause']\n",
    "    effects_candidates = cos_mat[row[0]].argsort()[-20:]\n",
    "    excluded_effects_index = get_excluded_effects_index(df_train_pos, row[0])\n",
    "    effects_candidates = np.setdiff1d(effects_candidates, excluded_effects_index)   # avoid choosing the true effect\n",
    "    if len(effects_candidates) == 0:\n",
    "        print('no candidates for row {}'.format(row[0]))\n",
    "        effects_candidates = cos_mat[row[0]].argsort()[-40:]\n",
    "        effects_candidates = np.setdiff1d(effects_candidates, excluded_effects_index)\n",
    "    choice = np.random.choice(effects_candidates)\n",
    "    neg_effect = df_train_pos.iloc[choice]['effect']\n",
    "    neg_list.append({'wiki_page': wiki_page, 'sentence': sentence, 'cause': cause, 'effect': neg_effect, 'ChatGPT_label': 0})\n",
    "    \n",
    "df_neg = pd.DataFrame(neg_list)\n",
    "df_train_new = pd.concat([df_train_pos, df_neg], ignore_index=True)\n",
    "\n",
    "df_train_new.to_csv('../Dataset/EconNLI_train_tmp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign labels by GPT-4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import openai\n",
    "import backoff\n",
    "import time\n",
    "\n",
    "openai.api_key = '' # put your openai api key here\n",
    "\n",
    "def prompt_gpt(prompt,model_name=\"gpt-3.5-turbo\"): \n",
    "    # model_name in [\"gpt-3.5-turbo\", \"gpt-4\", \"gpt-4o\"]\n",
    "    try:\n",
    "        completion = openai.ChatCompletion.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\":prompt}\n",
    "        ])\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        time.sleep(6)\n",
    "        completion = openai.ChatCompletion.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\":prompt}\n",
    "        ])\n",
    "    return completion[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "@backoff.on_exception(backoff.expo, openai.error.RateLimitError)\n",
    "def prompt_gpt_with_backoff(prompt,model_name=\"gpt-3.5-turbo\"):\n",
    "    return prompt_gpt(prompt, model_name)\n",
    "\n",
    "\n",
    "def relation_classification_via_gpt(cause, effect,model_name, sentence=None):\n",
    "    if sentence is None:\n",
    "        prompt = f\"Can we infer that {cause} is a cause of {effect} ? Answer Yes or No.\"\n",
    "    else:\n",
    "        prompt = f\" Given the sentence {sentence}, can we infer that {cause} is a cause of {effect} ? Answer Yes or No.\"  \n",
    "    response = prompt_gpt_with_backoff(prompt, model_name)\n",
    "    if response.strip(\"\\n\").strip(\".\").strip().lower() == \"yes\":\n",
    "        return 1\n",
    "    elif response.strip(\"\\n\").strip(\".\").strip().lower() == \"no\":\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    train_df = pd.read_csv(\"../Dataset/EconNLI_train_tmp.csv\",index_col=0)\n",
    "\n",
    "    for row in tqdm(train_df.iterrows(),total = len(train_df)):\n",
    "        results_GPT4 = []\n",
    "        if row[1][\"ChatGPT_label\"] == 1:\n",
    "            result_GPT4 = relation_classification_via_gpt(row[1][\"cause\"], row[1][\"effect\"], \"gpt-4\" ,sentence=row[1][\"sentence\"])\n",
    "        else:\n",
    "            result_GPT4 = relation_classification_via_gpt(row[1][\"cause\"], row[1][\"effect\"], \"gpt-4\")\n",
    "        results_GPT4.append(result_GPT4)\n",
    "        train_df.loc[row[0], \"GPT4_label\"] = results_GPT4\n",
    "        # time.sleep(2)  # avoid rate limit\n",
    "\n",
    "    train_df = train_df[~((train_df[\"ChatGPT_label\"] == 0) & (train_df[\"GPT4_label\"] == 1))]\n",
    "    train_df.to_csv(\"../Dataset/EconNLI_train_final.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
