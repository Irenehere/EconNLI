{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## relation extraction via linking phrase parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import openai\n",
    "import backoff\n",
    "import time\n",
    "\n",
    "openai.api_key = '' # put your key here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_sentence_fragments(phrase1, phrase2, events):\n",
    "    vectorizer = CountVectorizer().fit([phrase1, phrase2]+events)\n",
    "    events1, events2 = [], []\n",
    "    phrase1_vector = vectorizer.transform([phrase1])\n",
    "    phrase2_vector = vectorizer.transform([phrase2])\n",
    "    for event in events:\n",
    "        event_vector = vectorizer.transform([event])\n",
    "        if cosine_similarity(event_vector, phrase1_vector) > cosine_similarity(event_vector, phrase2_vector) :\n",
    "            events1.append(event)\n",
    "        else:\n",
    "            events2.append(event)\n",
    "    return events1, events2\n",
    "\n",
    "\n",
    "def extract_events_from_llama_labeled_events(string):\n",
    "    # Use a regular expression to find the desired text\n",
    "    matches = re.findall(r'\\d+\\.\\s*(.*?)\\s*(?=\\d+\\.|$)', string, re.DOTALL)\n",
    "    # Remove any empty or whitespace-only matches\n",
    "    matches = [match.strip(\" \\n.#\") for match in matches if match.strip()]\n",
    "    return matches\n",
    "\n",
    "\n",
    "def prompt_chatgpt(prompt):\n",
    "    try:\n",
    "        completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\":prompt}\n",
    "        ])\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        time.sleep(6)\n",
    "        completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\":prompt}\n",
    "        ])\n",
    "    return completion[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "@backoff.on_exception(backoff.expo, openai.error.RateLimitError)\n",
    "def prompt_chatgpt_with_backoff(prompt):\n",
    "    return prompt_chatgpt(prompt)\n",
    "\n",
    "\n",
    "def cause_classification_via_chatgpt(sentence, cause_candidates, effect_candidates):\n",
    "    results = []\n",
    "    for i in range(len(cause_candidates)):\n",
    "        for j in range(len(effect_candidates)):\n",
    "            cause = cause_candidates[i].replace(\"\\n\",\"\")\n",
    "            effect = effect_candidates[j].replace(\"\\n\",\"\")\n",
    "            prompt = f\" Given the sentence {sentence}, can we infer that {cause} is a cause of {effect} ? Answer Yes or No.\"  \n",
    "            response = prompt_chatgpt_with_backoff(prompt)\n",
    "            if response.strip(\"\\n\").strip(\".\").strip().lower() == \"yes\":\n",
    "                results.append(f\"{cause} ==> {effect}\")\n",
    "    return \"\\n\".join(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "cause_words = ['because', 'because of', 'owing to', 'due to', 'caused by']\n",
    "effect_words = ['so', 'therefore', 'hence', 'thus', 'as a result', ' as a consequence', 'consequently', 'resulting in', 'resulted in']\n",
    "cause_list = []\n",
    "effect_list = []\n",
    "\n",
    "files = os.listdir(\"../Corpus/llama_labeled_events\")\n",
    "for file in tqdm(files):\n",
    "    wiki_page = file.split(\".\")[0]\n",
    "    print(\"Processing wiki page:\",wiki_page)\n",
    "    try:\n",
    "        df = pd.read_csv(f\"../Corpus/llama_labeled_events/{file}\",index_col=0)\n",
    "    except UnicodeDecodeError:\n",
    "        continue\n",
    "    if len(df)==0:\n",
    "        continue\n",
    "    df_causes_filtered = df[df['sentence'].str.contains('[Bb]ecause|[Bb]ecause of|[Oo]wing to|[Dd]ue to|[Cc]aused by', regex=True)]\n",
    "    df_effects_filtered = df[df['sentence'].str.contains(' [Ss]o |[Tt]herefore|[Hh]ence |[Tt]hus |[Aa]s a result|[Aa]s a consequence|[Cc]onsequently|[Rr]esulting in|[Rr]esulted in', regex=True)]\n",
    "    \n",
    "\n",
    "    for row in df_causes_filtered.iterrows():\n",
    "        sentence = row[1].sentence.lower()\n",
    "        events = extract_events_from_llama_labeled_events(row[1].llama_labeled_events)\n",
    "\n",
    "        for word in cause_words:\n",
    "            if word in sentence:\n",
    "                try:\n",
    "                    phrase1, phrase2 = sentence.split(word)\n",
    "                except:\n",
    "                    continue\n",
    "                events1, events2 = match_sentence_fragments(phrase1, phrase2, events)\n",
    "                \n",
    "                if len(events1) == 0 or len(events2) == 0:\n",
    "                    continue\n",
    "\n",
    "                # # extract the cause-effect pair by rule\n",
    "                # if len(events1) == 1 and len(events2) == 1:\n",
    "                #     causes_inference_by_rule = f\"{events2[0]} ==> {events1[0]}\" \n",
    "                # else:\n",
    "                #     causes_inference_by_rule = \"\"\n",
    "\n",
    "                # extract the cause-effect pair by ChatGPT\n",
    "                causes_inference_by_ChatGPT = cause_classification_via_chatgpt(sentence, cause_candidates = events2, effect_candidates = events1)\n",
    "\n",
    "                # store the results into the list\n",
    "                if causes_inference_by_ChatGPT == \"\":\n",
    "                    continue\n",
    "                for cause_effect_pair in causes_inference_by_ChatGPT.split(\"\\n\"):\n",
    "                    cause, effect = cause_effect_pair.split(\" ==> \")\n",
    "                    cause_list.append({\n",
    "                        \"wiki_page\": wiki_page,\n",
    "                        \"sentence\": sentence,\n",
    "                        \"cause\": cause,\n",
    "                        \"effect\": effect,\n",
    "                        \"ChatGPT_label\":1,\n",
    "                    })\n",
    "\n",
    "    for row in df_effects_filtered.iterrows():\n",
    "        sentence = row[1].sentence.lower()\n",
    "        events = extract_events_from_llama_labeled_events(row[1].llama_labeled_events)\n",
    "        \n",
    "        for word in effect_words:\n",
    "            if word in sentence:\n",
    "                try:\n",
    "                    phrase1, phrase2 = sentence.split(word)\n",
    "                except:\n",
    "                    continue\n",
    "                events1, events2 = match_sentence_fragments(phrase1, phrase2, events)\n",
    "\n",
    "                if len(events1) == 0 or len(events2) == 0:\n",
    "                    continue\n",
    "\n",
    "                # # extract the cause-effect pair by rule\n",
    "                # if len(events1) == 1 and len(events2) == 1:\n",
    "                #     effect_inference_by_rule = f\"{events1[0]} ==> {events2[0]}\" \n",
    "                # else:\n",
    "                #     effect_inference_by_rule = \"\"\n",
    "\n",
    "                # extract the cause-effect pair by ChatGPT\n",
    "                effect_inference_by_ChatGPT = cause_classification_via_chatgpt(sentence, cause_candidates = events1, effect_candidates = events2)\n",
    "\n",
    "                # store the results into the list\n",
    "                if effect_inference_by_ChatGPT == \"\":\n",
    "                    continue\n",
    "                for cause_effect_pair in effect_inference_by_ChatGPT.split(\"\\n\"):\n",
    "                    cause, effect = cause_effect_pair.split(\" ==> \")\n",
    "                    effect_list.append({\n",
    "                        \"wiki_page\": wiki_page,\n",
    "                        \"sentence\": sentence,\n",
    "                        \"cause\": cause,\n",
    "                        \"effect\": effect,\n",
    "                        \"ChatGPT_label\":1,\n",
    "                    })\n",
    "    \n",
    "df_merged = pd.DataFrame(cause_list + effect_list)\n",
    "df_merged.to_csv(\"../Dataset/EconNLI_train_tmp.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
